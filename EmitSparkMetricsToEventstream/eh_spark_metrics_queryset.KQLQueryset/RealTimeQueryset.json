{"payload":{"connections":{"-946441554":{"clusterType":"Engine","name":"-946441554","connectionString":"","databases":{"-946441554/863036db-a4c6-8af0-472a-82dd517eb26c":{"id":"-946441554/863036db-a4c6-8af0-472a-82dd517eb26c","name":"863036db-a4c6-8af0-472a-82dd517eb26c","prettyName":"eh_spark_metrics","fetchState":"notStarted","fetchStateError":"","tables":{},"functions":{},"entityGroups":{},"accessMode":"ReadWrite","minorVersion":0,"majorVersion":15}},"id":"-946441554","fetchState":"notStarted","fetchStateError":"","tooBigToCache":true,"serviceOffering":"Trident"}},"tabs":[{"id":"f63b0f67-66ff-4a1f-9924-394b7f870556","queryRange":{"startLineNumber":1,"startColumn":1,"endLineNumber":12,"endColumn":1},"text":"spark_metrics\n| filter applicationName  == 'Spark-log-emitting-test'\n| filter category  == 'Metrics'\n| extend p = parse_json(properties)\n| project  metric = tostring(p.name), value = tolong(p.value), metric_type = p.metric_type, applicationName, timestamp, p, executorId\n| extend split  = extract_all(@'\\.(?P<k>\\w*)\\.(?P<v>[A-Za-z][\\w.]*)', metric)\n| extend machine = tostring(split[0][0]), m = tostring(split[0][1])\n| filter m == 'executor.filesystem.hdfs.read_bytes'\n//| filter  metric_type == \"Gauge\"\n//| distinct m\n| sort by m\n","commandInContext":"spark_metrics\n| filter applicationName  == 'Spark-log-emitting-test'\n| filter category  == 'Metrics'\n| extend p = parse_json(properties)\n| project  metric = tostring(p.name), value = tolong(p.value), metric_type = p.metric_type, applicationName, timestamp, p, executorId\n| extend split  = extract_all(@'\\.(?P<k>\\w*)\\.(?P<v>[A-Za-z][\\w.]*)', metric)\n| extend machine = tostring(split[0][0]), m = tostring(split[0][1])\n| filter m == 'executor.filesystem.hdfs.read_bytes'\n//| filter  metric_type == \"Gauge\"\n//| distinct m\n| sort by m\n","executionStatus":"done","clientRequestId":"Kusto.Web.RTA.Query;accf10c2-ba45-45e1-9732-6597fb641c7d;f915ebeb-782c-4eaf-9c46-f4f58fce906a","completionInfo":-1399280628,"entityInContext":"-946441554/863036db-a4c6-8af0-472a-82dd517eb26c","commandType":"Query","commandWithoutLeadingComments":"spark_metrics\n| filter applicationName  == 'Spark-log-emitting-test'\n| filter category  == 'Metrics'\n| extend p = parse_json(properties)\n| project  metric = tostring(p.name), value = tolong(p.value), metric_type = p.metric_type, applicationName, timestamp, p, executorId\n| extend split  = extract_all(@'\\.(?P<k>\\w*)\\.(?P<v>[A-Za-z][\\w.]*)', metric)\n| extend machine = tostring(split[0][0]), m = tostring(split[0][1])\n| filter m == 'executor.filesystem.hdfs.read_bytes'\n//| filter  metric_type == \"Gauge\"\n//| distinct m\n| sort by m\n","hideEmptyColumns":false,"cursorPosition":{"lineNumber":8,"column":51},"isProtectedMode":false}],"tabInContext":"f63b0f67-66ff-4a1f-9924-394b7f870556"}}